{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "joined-newspaper",
   "metadata": {},
   "source": [
    "### Multi-Task Learning Pipeline\n",
    "\n",
    "Install the Jupyter notebook kernel with `python3 -m ipykernel install --user --name arise --display-name \"ARISE\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handy-optimum",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jknofczy/miniconda3/envs/arise/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jknofczy/miniconda3/envs/arise/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Defaulting to CPU.\n"
     ]
    }
   ],
   "source": [
    "from tsfresh import extract_features, extract_relevant_features\n",
    "import sys, os, math, random, glob, torch\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from utils import *\n",
    "from tsfresh.feature_extraction.feature_calculators import set_property\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DATA_DIR = get_full_path(\"data_28\") + \"/\"\n",
    "FIGURE_DIR = get_full_path(\"MTL\", \"Figures\") + \"/\"\n",
    "\n",
    "CUDA_INDEX = 0 # 0..2 for Mitra, -1 to disable (force CPU)\n",
    "# CUDA_INDEX = -1\n",
    "\n",
    "# Device Configuration\n",
    "if torch.cuda.is_available() and CUDA_INDEX >= 0:\n",
    "    device = torch.device(f'cuda:{CUDA_INDEX}') # MITRA has 3 CUDA GPUs available; use the third.\n",
    "    torch.cuda.set_device(CUDA_INDEX)\n",
    "else:\n",
    "    print(\"Warning: Defaulting to CPU.\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19c41a4",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snorkel==0.9.6\n",
      "  Using cached https://files.pythonhosted.org/packages/4e/6a/e33babd8b4fb34867b695b5ab6b02c9106ec9de05ed4a02b2b9417eb3ae7/snorkel-0.9.6-py3-none-any.whl\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from snorkel==0.9.6) (1.19.5)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.2.0 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from snorkel==0.9.6) (1.9.0)\n",
      "Requirement already satisfied: scikit-learn<0.22.0,>=0.20.2 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from snorkel==0.9.6) (0.21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.33.0 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from snorkel==0.9.6) (4.62.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from snorkel==0.9.6) (1.2.1)\n",
      "Requirement already satisfied: munkres>=1.0.6 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from snorkel==0.9.6) (1.1.4)\n",
      "Requirement already satisfied: pandas<2.0.0,>=0.25.0 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from snorkel==0.9.6) (1.1.5)\n",
      "Requirement already satisfied: networkx<2.4,>=2.2 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from snorkel==0.9.6) (2.3)\n",
      "Requirement already satisfied: tensorboard<2.0.0,>=1.14.0 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from snorkel==0.9.6) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from torch<2.0.0,>=1.2.0->snorkel==0.9.6) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from torch<2.0.0,>=1.2.0->snorkel==0.9.6) (0.8)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from scikit-learn<0.22.0,>=0.20.2->snorkel==0.9.6) (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from pandas<2.0.0,>=0.25.0->snorkel==0.9.6) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from pandas<2.0.0,>=0.25.0->snorkel==0.9.6) (2.8.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from networkx<2.4,>=2.2->snorkel==0.9.6) (5.0.9)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from tensorboard<2.0.0,>=1.14.0->snorkel==0.9.6) (49.6.0.post20210108)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from tensorboard<2.0.0,>=1.14.0->snorkel==0.9.6) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from tensorboard<2.0.0,>=1.14.0->snorkel==0.9.6) (2.0.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from tensorboard<2.0.0,>=1.14.0->snorkel==0.9.6) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from tensorboard<2.0.0,>=1.14.0->snorkel==0.9.6) (3.17.3)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from tensorboard<2.0.0,>=1.14.0->snorkel==0.9.6) (0.36.2)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from tensorboard<2.0.0,>=1.14.0->snorkel==0.9.6) (1.39.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from tensorboard<2.0.0,>=1.14.0->snorkel==0.9.6) (0.13.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.0.0,>=1.14.0->snorkel==0.9.6) (4.8.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jared/miniconda3/envs/arise/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.0.0,>=1.14.0->snorkel==0.9.6) (3.5.0)\n",
      "Installing collected packages: snorkel\n",
      "  Found existing installation: snorkel 0.9.7\n",
      "    Uninstalling snorkel-0.9.7:\n",
      "      Successfully uninstalled snorkel-0.9.7\n",
      "Successfully installed snorkel-0.9.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If there are issues after first booting the project, verify the proper version of Snorkel is installed.\n",
    "%pip install snorkel==0.9.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-mention",
   "metadata": {},
   "source": [
    "### Load in raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "important-chair",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "raw = get_all_datasets() # from utils.py\n",
    "master = raw\n",
    "# master.to_csv(ROOT_DIR + \"/MTL/data/Master Dataset.csv\", encoding='utf-8', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-athletics",
   "metadata": {},
   "source": [
    "### Feature Extraction using `tsfresh`  \n",
    "First, we define the custom set of features that we wish to extract.  \n",
    "Then, we choose which features will be actually extracted and we perform the extraction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "induced-strain",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from tsfresh.feature_extraction.feature_calculators import set_property\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def count_nonzero(x):\n",
    "    \"\"\" Returns the number of nonzero (non-loss) measurements in the time series x. \"\"\"\n",
    "    return np.count_nonzero(x)\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def noise_threshold(x):\n",
    "    \"\"\" Returns the noise threshold for a time series \n",
    "        by taking 1.5 * the RTT value at the 75th percentile. \"\"\"\n",
    "    x = x[x != 0] # remove all loss points from consideration\n",
    "    return np.percentile(x, 75) * 1.5\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def congestion_threshold(x):\n",
    "    \"\"\" Returns the congestion threshold for a time series \n",
    "        by taking 1.2 * the RTT value at the 30th percentile. \"\"\"\n",
    "    x = x[x != 0] # remove all loss points from consideration\n",
    "    return np.percentile(x, 30) * 1.2\n",
    "\n",
    "\n",
    "# Add custom features to list of feature calculators:\n",
    "# feature_calculators.__dict__[\"num_outages\"] = num_outages\n",
    "feature_calculators.__dict__[\"count_nonzero\"] = count_nonzero\n",
    "feature_calculators.__dict__[\"noise_thresh\"] = noise_threshold\n",
    "feature_calculators.__dict__[\"congestion_thresh\"] = congestion_threshold\n",
    "\n",
    "# https://tsfresh.readthedocs.io/en/latest/text/feature_extraction_settings.html\n",
    "\n",
    "custom = {\n",
    "    \"quantile\": [{\"q\": 0.75}], # 75% means this is the point at which it is higher value than 75% of all data points.\n",
    "    \"median\": None,\n",
    "    \"mean\": None,\n",
    "    \"standard_deviation\": None,\n",
    "    \"noise_thresh\": None,\n",
    "    \"congestion_thresh\": None,\n",
    "#     \"large_standard_deviation\": [{'r': 0.1}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advised-annual",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 28/28 [00:00<00:00, 432.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rtt__quantile__q_0.75</th>\n",
       "      <th>rtt__median</th>\n",
       "      <th>rtt__mean</th>\n",
       "      <th>rtt__standard_deviation</th>\n",
       "      <th>rtt__noise_threshold</th>\n",
       "      <th>rtt__congestion_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.12300</td>\n",
       "      <td>27.0065</td>\n",
       "      <td>33.82896</td>\n",
       "      <td>30.52835</td>\n",
       "      <td>45.18450</td>\n",
       "      <td>30.12324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.65950</td>\n",
       "      <td>13.9430</td>\n",
       "      <td>19.80178</td>\n",
       "      <td>27.79079</td>\n",
       "      <td>24.98925</td>\n",
       "      <td>14.60280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.49200</td>\n",
       "      <td>26.6660</td>\n",
       "      <td>32.39799</td>\n",
       "      <td>33.78114</td>\n",
       "      <td>44.23800</td>\n",
       "      <td>29.90136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140.34050</td>\n",
       "      <td>105.0420</td>\n",
       "      <td>91.60246</td>\n",
       "      <td>59.13177</td>\n",
       "      <td>210.51075</td>\n",
       "      <td>38.58852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.74100</td>\n",
       "      <td>32.8490</td>\n",
       "      <td>38.56521</td>\n",
       "      <td>27.53349</td>\n",
       "      <td>53.61150</td>\n",
       "      <td>37.37784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.09100</td>\n",
       "      <td>15.5560</td>\n",
       "      <td>24.74454</td>\n",
       "      <td>32.59514</td>\n",
       "      <td>33.13650</td>\n",
       "      <td>16.03344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.69800</td>\n",
       "      <td>30.8610</td>\n",
       "      <td>36.51597</td>\n",
       "      <td>26.83374</td>\n",
       "      <td>50.54700</td>\n",
       "      <td>34.85040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.75750</td>\n",
       "      <td>13.5705</td>\n",
       "      <td>20.87237</td>\n",
       "      <td>33.35229</td>\n",
       "      <td>25.13625</td>\n",
       "      <td>14.18400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.61100</td>\n",
       "      <td>15.4570</td>\n",
       "      <td>23.79601</td>\n",
       "      <td>29.80547</td>\n",
       "      <td>32.41650</td>\n",
       "      <td>15.91152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29.30550</td>\n",
       "      <td>26.4845</td>\n",
       "      <td>32.68720</td>\n",
       "      <td>31.35319</td>\n",
       "      <td>43.95825</td>\n",
       "      <td>29.73468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.06300</td>\n",
       "      <td>32.3710</td>\n",
       "      <td>39.03651</td>\n",
       "      <td>33.74868</td>\n",
       "      <td>54.09450</td>\n",
       "      <td>36.61704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>82.47550</td>\n",
       "      <td>76.6640</td>\n",
       "      <td>83.03644</td>\n",
       "      <td>25.83421</td>\n",
       "      <td>123.71325</td>\n",
       "      <td>89.25864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>130.77475</td>\n",
       "      <td>103.5830</td>\n",
       "      <td>85.58553</td>\n",
       "      <td>58.90030</td>\n",
       "      <td>196.16212</td>\n",
       "      <td>34.40760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30.24550</td>\n",
       "      <td>27.4310</td>\n",
       "      <td>33.28327</td>\n",
       "      <td>27.46912</td>\n",
       "      <td>45.36825</td>\n",
       "      <td>30.91920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.45600</td>\n",
       "      <td>14.0300</td>\n",
       "      <td>19.60216</td>\n",
       "      <td>30.64830</td>\n",
       "      <td>26.18400</td>\n",
       "      <td>14.61336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>63.00300</td>\n",
       "      <td>59.2155</td>\n",
       "      <td>66.34261</td>\n",
       "      <td>33.55233</td>\n",
       "      <td>94.50450</td>\n",
       "      <td>68.52576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35.47500</td>\n",
       "      <td>32.8385</td>\n",
       "      <td>39.05005</td>\n",
       "      <td>32.39860</td>\n",
       "      <td>53.21250</td>\n",
       "      <td>37.46340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29.40900</td>\n",
       "      <td>26.6320</td>\n",
       "      <td>32.25403</td>\n",
       "      <td>27.29606</td>\n",
       "      <td>44.11350</td>\n",
       "      <td>29.79864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>81.55300</td>\n",
       "      <td>46.3740</td>\n",
       "      <td>65.60014</td>\n",
       "      <td>45.96976</td>\n",
       "      <td>122.32950</td>\n",
       "      <td>43.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>57.53050</td>\n",
       "      <td>54.8350</td>\n",
       "      <td>61.84945</td>\n",
       "      <td>34.20462</td>\n",
       "      <td>86.29575</td>\n",
       "      <td>63.62232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29.78775</td>\n",
       "      <td>26.5045</td>\n",
       "      <td>32.06265</td>\n",
       "      <td>25.67596</td>\n",
       "      <td>44.68162</td>\n",
       "      <td>29.51484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>33.46900</td>\n",
       "      <td>30.7220</td>\n",
       "      <td>37.05294</td>\n",
       "      <td>29.48559</td>\n",
       "      <td>50.20350</td>\n",
       "      <td>34.71840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30.27300</td>\n",
       "      <td>27.4410</td>\n",
       "      <td>32.96008</td>\n",
       "      <td>26.52787</td>\n",
       "      <td>45.40950</td>\n",
       "      <td>30.82392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>74.19800</td>\n",
       "      <td>71.4900</td>\n",
       "      <td>78.10052</td>\n",
       "      <td>34.40099</td>\n",
       "      <td>111.29700</td>\n",
       "      <td>83.64720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.88900</td>\n",
       "      <td>13.9830</td>\n",
       "      <td>19.86964</td>\n",
       "      <td>27.62778</td>\n",
       "      <td>25.33350</td>\n",
       "      <td>14.60580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.04750</td>\n",
       "      <td>13.8020</td>\n",
       "      <td>20.17250</td>\n",
       "      <td>28.41753</td>\n",
       "      <td>25.57125</td>\n",
       "      <td>14.39160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>57.57575</td>\n",
       "      <td>54.9760</td>\n",
       "      <td>61.00102</td>\n",
       "      <td>27.98829</td>\n",
       "      <td>86.36362</td>\n",
       "      <td>63.62520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>35.45950</td>\n",
       "      <td>32.1000</td>\n",
       "      <td>38.98793</td>\n",
       "      <td>33.56582</td>\n",
       "      <td>53.18925</td>\n",
       "      <td>36.33672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rtt__quantile__q_0.75  rtt__median  rtt__mean  rtt__standard_deviation  \\\n",
       "0                30.12300      27.0065   33.82896                 30.52835   \n",
       "1                16.65950      13.9430   19.80178                 27.79079   \n",
       "2                29.49200      26.6660   32.39799                 33.78114   \n",
       "3               140.34050     105.0420   91.60246                 59.13177   \n",
       "4                35.74100      32.8490   38.56521                 27.53349   \n",
       "5                22.09100      15.5560   24.74454                 32.59514   \n",
       "6                33.69800      30.8610   36.51597                 26.83374   \n",
       "7                16.75750      13.5705   20.87237                 33.35229   \n",
       "8                21.61100      15.4570   23.79601                 29.80547   \n",
       "9                29.30550      26.4845   32.68720                 31.35319   \n",
       "10               36.06300      32.3710   39.03651                 33.74868   \n",
       "11               82.47550      76.6640   83.03644                 25.83421   \n",
       "12              130.77475     103.5830   85.58553                 58.90030   \n",
       "13               30.24550      27.4310   33.28327                 27.46912   \n",
       "14               17.45600      14.0300   19.60216                 30.64830   \n",
       "15               63.00300      59.2155   66.34261                 33.55233   \n",
       "16               35.47500      32.8385   39.05005                 32.39860   \n",
       "17               29.40900      26.6320   32.25403                 27.29606   \n",
       "18               81.55300      46.3740   65.60014                 45.96976   \n",
       "19               57.53050      54.8350   61.84945                 34.20462   \n",
       "20               29.78775      26.5045   32.06265                 25.67596   \n",
       "21               33.46900      30.7220   37.05294                 29.48559   \n",
       "22               30.27300      27.4410   32.96008                 26.52787   \n",
       "23               74.19800      71.4900   78.10052                 34.40099   \n",
       "24               16.88900      13.9830   19.86964                 27.62778   \n",
       "25               17.04750      13.8020   20.17250                 28.41753   \n",
       "26               57.57575      54.9760   61.00102                 27.98829   \n",
       "27               35.45950      32.1000   38.98793                 33.56582   \n",
       "\n",
       "    rtt__noise_threshold  rtt__congestion_threshold  \n",
       "0               45.18450                   30.12324  \n",
       "1               24.98925                   14.60280  \n",
       "2               44.23800                   29.90136  \n",
       "3              210.51075                   38.58852  \n",
       "4               53.61150                   37.37784  \n",
       "5               33.13650                   16.03344  \n",
       "6               50.54700                   34.85040  \n",
       "7               25.13625                   14.18400  \n",
       "8               32.41650                   15.91152  \n",
       "9               43.95825                   29.73468  \n",
       "10              54.09450                   36.61704  \n",
       "11             123.71325                   89.25864  \n",
       "12             196.16212                   34.40760  \n",
       "13              45.36825                   30.91920  \n",
       "14              26.18400                   14.61336  \n",
       "15              94.50450                   68.52576  \n",
       "16              53.21250                   37.46340  \n",
       "17              44.11350                   29.79864  \n",
       "18             122.32950                   43.95000  \n",
       "19              86.29575                   63.62232  \n",
       "20              44.68162                   29.51484  \n",
       "21              50.20350                   34.71840  \n",
       "22              45.40950                   30.82392  \n",
       "23             111.29700                   83.64720  \n",
       "24              25.33350                   14.60580  \n",
       "25              25.57125                   14.39160  \n",
       "26              86.36362                   63.62520  \n",
       "27              53.18925                   36.33672  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disable_progress_bar = True\n",
    "disable_progress_bar = False\n",
    "\n",
    "\"\"\" ----- Select dataframe to extract features on ----- \"\"\"\n",
    "df = master  # CAIDA 28 datasets\n",
    "# caida_features = extract_features(master, default_fc_parameters=custom, column_id=\"id\", \\\n",
    "#                             column_sort=\"index\", column_value=\"rtt\", \\\n",
    "#                             disable_progressbar=disable_progress_bar).round(5)\n",
    "\n",
    "\n",
    "\"\"\" Uncomment to use RIPE Atlas Data. \"\"\"\n",
    "## df = pd.read_csv(\"data/RIPE Atlas Dataset.csv\") # removed to save space, 5/6/2021\n",
    "# df = pd.read_csv(\"data/RIPE_changepoint.csv\", index_col=\"Unnamed: 0\") # use this to load pre-labeled ripe dataset\n",
    "# df.rename(columns={'Unnamed: 0.1':'index'}, inplace=True)\n",
    "\n",
    "\n",
    "\"\"\" Perform feature extraction with custom settings \"\"\"\n",
    "features = extract_features(df, default_fc_parameters=custom, column_id=\"id\", \\\n",
    "                            column_sort=\"index\", column_value=\"rtt\", \\\n",
    "                            disable_progressbar=disable_progress_bar).round(5)\n",
    "\n",
    "# features.to_csv(ROOT_DIR + \"/MTL/Features.csv\", encoding='utf-8', header=True)\n",
    "# features.to_csv(ROOT_DIR + \"/MTL/RIPE Atlas Features.csv\", encoding='utf-8', header=True)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-skill",
   "metadata": {},
   "source": [
    "### Building LFs and Synthesizing new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mature-cattle",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "VOTE    =  1\n",
    "NORMAL  =  0\n",
    "ABSTAIN = -1\n",
    "\n",
    "def label_noise(rtt, client_index):\n",
    "    noise_threshold = features['rtt__noise_threshold'][client_index]\n",
    "    if rtt >= noise_threshold:\n",
    "        label = VOTE\n",
    "    else:\n",
    "        label = NORMAL\n",
    "    return label\n",
    "\n",
    "def label_outage(rtt, client_index):\n",
    "    if rtt == 0:\n",
    "        label = VOTE\n",
    "    else:\n",
    "        label = NORMAL\n",
    "    return label\n",
    "\n",
    "def label_congestion(rtt, client_index):\n",
    "    cong_threshold = features['rtt__congestion_threshold'][client_index]\n",
    "    noise_threshold = features['rtt__noise_threshold'][client_index]\n",
    "    \n",
    "    if rtt >= cong_threshold and rtt < noise_threshold:\n",
    "        label = VOTE\n",
    "    else:\n",
    "        label = NORMAL\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "def generate_data(df):\n",
    "    \"\"\" DF should be a labeled, original dataset. \"\"\"\n",
    "    global features\n",
    "\n",
    "    newdata = pd.DataFrame(columns=[\"id\", \"i\", \"rtt\", \"loss\", \"congestion\", \"noise\"])\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        # print(f\"Index {i}; data: \\n{row['rtt']}\\n\")\n",
    "        ID = row['id']\n",
    "        \n",
    "        try:\n",
    "            index = row['i']\n",
    "        except:\n",
    "            index = row['index']\n",
    "        \n",
    "        # Appending original data\n",
    "        rtt = row['rtt']\n",
    "        l, c, n = (row['loss'], row['congestion'], row['noise']) # labels\n",
    "        newdata = newdata.append({'id': ID, 'i': index, 'rtt': rtt, 'loss': l, 'congestion': c, 'noise': n}, ignore_index=True)\n",
    "        \n",
    "        # Appending synthesized data -- loss\n",
    "        rtt = 0\n",
    "        l, c, n = (VOTE, NORMAL, NORMAL) # labels\n",
    "        newdata = newdata.append({'id': ID, 'i': index, 'rtt': rtt, 'loss': l, 'congestion': c, 'noise': n}, ignore_index=True)\n",
    "        \n",
    "        # Appending synthesized data -- congestion\n",
    "        cong_threshold = features['rtt__congestion_threshold'][ID]\n",
    "        noise_thresh = features['rtt__noise_threshold'][ID]\n",
    "        rtt = np.random.randint(cong_threshold, noise_thresh)\n",
    "        l, c, n = (NORMAL, VOTE, NORMAL) # labels\n",
    "        newdata = newdata.append({'id': ID, 'i': index, 'rtt': rtt, 'loss': l, 'congestion': c, 'noise': n}, ignore_index=True)\n",
    "            \n",
    "        # Appending synthesized data -- noise\n",
    "        noise_scale = 5 # scale upper bound for noise by this. original is 4.\n",
    "        gap = 500 # ensure a gap of at least XXms between synthetic congestion and noise RTT values\n",
    "        noise_thresh = features['rtt__noise_threshold'][ID]\n",
    "        rtt = np.random.randint(noise_thresh + gap, noise_thresh * noise_scale + gap)\n",
    "        l, c, n = (NORMAL, NORMAL, VOTE) # labels\n",
    "        newdata = newdata.append({'id': ID, 'i': index, 'rtt': rtt, 'loss': l, 'congestion': c, 'noise': n}, ignore_index=True)\n",
    "    \n",
    "    return newdata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-trinidad",
   "metadata": {},
   "source": [
    "### Here, we can synthesize new data for use with Snorkel. This should only need to be done once; the data can be loaded from `~/multitaskws/MTL/data/synth.csv` rather than being generated again.  \n",
    "\n",
    "#### This can be skipped if using the larger RIPE Atlas Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0bb34f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>index</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rtt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 12:50:15</td>\n",
       "      <td>29.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 12:50:17</td>\n",
       "      <td>29.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 12:50:17</td>\n",
       "      <td>32.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 12:50:17</td>\n",
       "      <td>26.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 12:50:19</td>\n",
       "      <td>32.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-01 12:51:37</td>\n",
       "      <td>27.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-01 12:51:37</td>\n",
       "      <td>25.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-01-01 12:52:13</td>\n",
       "      <td>23.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-01 12:52:38</td>\n",
       "      <td>26.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-01-01 12:52:38</td>\n",
       "      <td>25.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-01-01 12:52:40</td>\n",
       "      <td>24.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2019-01-01 12:52:41</td>\n",
       "      <td>24.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-01 12:52:41</td>\n",
       "      <td>24.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2019-01-01 12:52:41</td>\n",
       "      <td>24.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2019-01-01 12:52:43</td>\n",
       "      <td>23.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-01-01 12:52:45</td>\n",
       "      <td>25.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2019-01-01 12:52:46</td>\n",
       "      <td>24.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2019-01-01 12:53:35</td>\n",
       "      <td>25.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2019-01-01 12:54:53</td>\n",
       "      <td>31.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2019-01-01 12:54:53</td>\n",
       "      <td>31.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2019-01-01 12:54:55</td>\n",
       "      <td>28.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-01-01 12:54:58</td>\n",
       "      <td>30.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-01-01 12:55:44</td>\n",
       "      <td>30.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2019-01-01 12:55:45</td>\n",
       "      <td>30.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2019-01-01 12:55:46</td>\n",
       "      <td>31.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2019-01-01 12:55:46</td>\n",
       "      <td>24.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2019-01-01 12:58:38</td>\n",
       "      <td>26.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2019-01-01 12:58:38</td>\n",
       "      <td>27.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2019-01-01 12:58:38</td>\n",
       "      <td>26.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2019-01-01 12:58:39</td>\n",
       "      <td>23.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75329</th>\n",
       "      <td>27</td>\n",
       "      <td>2849</td>\n",
       "      <td>2019-01-02 00:01:21</td>\n",
       "      <td>30.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75330</th>\n",
       "      <td>27</td>\n",
       "      <td>2850</td>\n",
       "      <td>2019-01-02 00:01:22</td>\n",
       "      <td>31.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75331</th>\n",
       "      <td>27</td>\n",
       "      <td>2851</td>\n",
       "      <td>2019-01-02 00:01:25</td>\n",
       "      <td>28.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75332</th>\n",
       "      <td>27</td>\n",
       "      <td>2852</td>\n",
       "      <td>2019-01-02 00:01:25</td>\n",
       "      <td>32.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75333</th>\n",
       "      <td>27</td>\n",
       "      <td>2853</td>\n",
       "      <td>2019-01-02 00:01:26</td>\n",
       "      <td>31.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75334</th>\n",
       "      <td>27</td>\n",
       "      <td>2854</td>\n",
       "      <td>2019-01-02 00:01:27</td>\n",
       "      <td>30.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75335</th>\n",
       "      <td>27</td>\n",
       "      <td>2855</td>\n",
       "      <td>2019-01-02 00:01:32</td>\n",
       "      <td>29.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75336</th>\n",
       "      <td>27</td>\n",
       "      <td>2856</td>\n",
       "      <td>2019-01-02 00:02:14</td>\n",
       "      <td>30.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75337</th>\n",
       "      <td>27</td>\n",
       "      <td>2857</td>\n",
       "      <td>2019-01-02 00:02:15</td>\n",
       "      <td>31.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75338</th>\n",
       "      <td>27</td>\n",
       "      <td>2858</td>\n",
       "      <td>2019-01-02 00:02:16</td>\n",
       "      <td>28.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75339</th>\n",
       "      <td>27</td>\n",
       "      <td>2859</td>\n",
       "      <td>2019-01-02 00:02:17</td>\n",
       "      <td>29.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75340</th>\n",
       "      <td>27</td>\n",
       "      <td>2860</td>\n",
       "      <td>2019-01-02 00:02:20</td>\n",
       "      <td>30.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75341</th>\n",
       "      <td>27</td>\n",
       "      <td>2861</td>\n",
       "      <td>2019-01-02 00:02:20</td>\n",
       "      <td>32.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75342</th>\n",
       "      <td>27</td>\n",
       "      <td>2862</td>\n",
       "      <td>2019-01-02 00:02:21</td>\n",
       "      <td>28.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75343</th>\n",
       "      <td>27</td>\n",
       "      <td>2863</td>\n",
       "      <td>2019-01-02 00:03:15</td>\n",
       "      <td>43.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75344</th>\n",
       "      <td>27</td>\n",
       "      <td>2864</td>\n",
       "      <td>2019-01-02 00:03:16</td>\n",
       "      <td>29.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75345</th>\n",
       "      <td>27</td>\n",
       "      <td>2865</td>\n",
       "      <td>2019-01-02 00:03:18</td>\n",
       "      <td>36.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75346</th>\n",
       "      <td>27</td>\n",
       "      <td>2866</td>\n",
       "      <td>2019-01-02 00:03:21</td>\n",
       "      <td>29.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75347</th>\n",
       "      <td>27</td>\n",
       "      <td>2867</td>\n",
       "      <td>2019-01-02 00:03:50</td>\n",
       "      <td>34.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75348</th>\n",
       "      <td>27</td>\n",
       "      <td>2868</td>\n",
       "      <td>2019-01-02 00:03:51</td>\n",
       "      <td>29.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75349</th>\n",
       "      <td>27</td>\n",
       "      <td>2869</td>\n",
       "      <td>2019-01-02 00:03:53</td>\n",
       "      <td>28.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75350</th>\n",
       "      <td>27</td>\n",
       "      <td>2870</td>\n",
       "      <td>2019-01-02 00:03:53</td>\n",
       "      <td>30.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75351</th>\n",
       "      <td>27</td>\n",
       "      <td>2871</td>\n",
       "      <td>2019-01-02 00:04:01</td>\n",
       "      <td>30.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75352</th>\n",
       "      <td>27</td>\n",
       "      <td>2872</td>\n",
       "      <td>2019-01-02 00:04:38</td>\n",
       "      <td>31.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75353</th>\n",
       "      <td>27</td>\n",
       "      <td>2873</td>\n",
       "      <td>2019-01-02 00:04:38</td>\n",
       "      <td>29.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75354</th>\n",
       "      <td>27</td>\n",
       "      <td>2874</td>\n",
       "      <td>2019-01-02 00:04:42</td>\n",
       "      <td>29.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75355</th>\n",
       "      <td>27</td>\n",
       "      <td>2875</td>\n",
       "      <td>2019-01-02 00:04:42</td>\n",
       "      <td>29.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75356</th>\n",
       "      <td>27</td>\n",
       "      <td>2876</td>\n",
       "      <td>2019-01-02 00:04:44</td>\n",
       "      <td>37.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75357</th>\n",
       "      <td>27</td>\n",
       "      <td>2877</td>\n",
       "      <td>2019-01-02 00:04:48</td>\n",
       "      <td>28.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75358</th>\n",
       "      <td>27</td>\n",
       "      <td>2878</td>\n",
       "      <td>2019-01-02 00:05:25</td>\n",
       "      <td>30.681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75359 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id index             datetime     rtt\n",
       "0       0     0  2019-01-01 12:50:15  29.445\n",
       "1       0     1  2019-01-01 12:50:17  29.688\n",
       "2       0     2  2019-01-01 12:50:17  32.005\n",
       "3       0     3  2019-01-01 12:50:17  26.295\n",
       "4       0     4  2019-01-01 12:50:19  32.008\n",
       "...    ..   ...                  ...     ...\n",
       "75354  27  2874  2019-01-02 00:04:42  29.648\n",
       "75355  27  2875  2019-01-02 00:04:42  29.737\n",
       "75356  27  2876  2019-01-02 00:04:44  37.092\n",
       "75357  27  2877  2019-01-02 00:04:48  28.937\n",
       "75358  27  2878  2019-01-02 00:05:25  30.681\n",
       "\n",
       "[75359 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "progressive-raising",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Read synth data from CSV by default, otherwise, synthesize it again.\n",
    "#     synth = pd.read_csv(\"data/synth.csv\", index_col=0)\n",
    "    synth = pd.read_csv(\"data/synth_gap500.csv\", index_col=0) # default\n",
    "    # synth = pd.read_csv(\"data/synth_latest.csv\", index_col=0) # adds changepoint, ddos labels\n",
    "except:\n",
    "    df = master\n",
    "    new_df = pd.DataFrame(columns=['id', 'i', 'datetime', 'rtt']) # empty dataframe to append modified DataFrames to\n",
    "    \n",
    "    \n",
    "    for client_id in range(28):\n",
    "        \"\"\" Synthesize data for better performance with weak supervision. \"\"\"\n",
    "        print(f\"Synthesizing data for client {client_id:02d}...\")\n",
    "\n",
    "        current_df = df[df['id'] == client_id] # df containing only values for current client\n",
    "        noise_threshold = features['rtt__noise_threshold'][client_id]\n",
    "        cong_threshold = features['rtt__congestion_threshold'][client_id]\n",
    "\n",
    "        # Apply labeling functions to original datasets.\n",
    "        current_df['loss'] = current_df['rtt'].apply(lambda x: label_outage(x, client_id))\n",
    "        current_df['congestion'] = current_df['rtt'].apply(lambda x: label_congestion(x, client_id))\n",
    "        current_df['noise'] = current_df['rtt'].apply(lambda x: label_noise(x, client_id))\n",
    "        current_df.rename(columns = {'index':'i'}, inplace=True)\n",
    "        del current_df['datetime']\n",
    "\n",
    "        # Synthesize new data in line with the current df.\n",
    "        current_df = generate_data(current_df)\n",
    "\n",
    "        new_df = new_df.append(current_df) # append modified dataframes to new modified set\n",
    "\n",
    "    new_df = new_df.astype({\"id\": 'int', \"i\": 'int', \"loss\": 'int', \\\n",
    "                            \"congestion\": 'int', \"noise\": 'int'}) # trim labels to ints, rather than floats\n",
    "\n",
    "    synth = new_df.reset_index(drop=True)\n",
    "    del synth[\"datetime\"]\n",
    "    print(\"Done.\")\n",
    "    \n",
    "    # synth.to_csv(\"data/synth.csv\", encoding='utf-8', header=True)\n",
    "    # synth.to_csv(\"data/synth_latest.csv\", encoding='utf-8', header=True)\n",
    "    synth.to_csv(\"data/synth_gap500.csv\", encoding='utf-8', header=True)\n",
    "\n",
    "\n",
    "# print(synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "healthy-authority",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Uncomment to display and save the figures of the new synthesized RTTs. \"\"\"\n",
    "save_figs = False\n",
    "# visualize_rtts(new_data, log_scale=True, swells=features['rtt__congestion_threshold'], \\\n",
    "#                noises=features['rtt__noise_threshold'], save_figures=save_figs, prefix=\"annotated\")\n",
    "\n",
    "# visualize_rtts(synth, log_scale=True, swells=features['rtt__congestion_threshold'], \\\n",
    "#                noises=features['rtt__noise_threshold'], save_figures=save_figs, prefix=\"annotated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420c3b4",
   "metadata": {},
   "source": [
    "### Adding Changepoint, DDoS Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "589078f0",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' CHANGEPOINT: anything where the distance of a point to the average \\n    of its neighbors is greater than 2x the mean distance '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOTE    =  1\n",
    "NORMAL  =  0\n",
    "ABSTAIN = -1\n",
    "\n",
    "def dist(current, target):\n",
    "    return abs(target-current)\n",
    "\n",
    "def label_change(x, client_index):\n",
    "#     change_thresh = features['rtt__standard_deviation'][client_index]\n",
    "    change_thresh = features['rtt__standard_deviation'][client_index] / 2 # 60% accuracy\n",
    "#     change_thresh = features['rtt__standard_deviation'][client_index] / 3 # 77% accuracy\n",
    "#     change_thresh = features['rtt__standard_deviation'][client_index] / 4 # 84% accuracy\n",
    "    \n",
    "#     if x > 30: # this used for CAIDA\n",
    "    if x > change_thresh:\n",
    "        return VOTE\n",
    "    else:\n",
    "        return NORMAL\n",
    "\n",
    "def label_OR(x, y):\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    return x | y\n",
    "\n",
    "def label_AND(x, y):\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    return x & y\n",
    "    \n",
    "\"\"\" CHANGEPOINT: anything where the distance of a point to the average \n",
    "    of its neighbors is greater than 2x the mean distance \"\"\" \n",
    "### ripe['WMA'] = ripe['rtt'].rolling(window=3, center=True, win_type ='triang').mean() # neighbors\n",
    "# ripe['WMA'] = ripe['rtt'].rolling(window=3, center=False, win_type ='triang').mean() # priors\n",
    "# ripe['WMA'].fillna(value=0, inplace=True)\n",
    "# ripe['dist'] = ripe.apply(lambda x: dist(x.rtt, x.WMA), axis=1)\n",
    "# ripe['changepoint'] = ripe.apply(lambda x: label_change(x.dist, x.id), axis=1)\n",
    "# ripe.to_csv('data/RIPE_changepoint.csv', header=True, encoding='utf-8')\n",
    "\n",
    "\n",
    "# synth['WMA'] = synth['rtt'].rolling(window=3, center=True, win_type ='triang').mean()\n",
    "# synth['WMA'].fillna(value=0, inplace=True)\n",
    "# synth['dist'] = synth.apply(lambda x: dist(x.rtt, x.WMA), axis=1)\n",
    "# synth['changepoint'] = synth['dist'].apply(lambda x: label_change(x))\n",
    "# synth['changepoint'] = synth['dist'].apply(lambda x: label_change(x))\n",
    "# synth.to_csv('data/synth_latest.csv', header=True, encoding='utf-8')\n",
    "# synth[\"task1\"] = synth.apply(lambda x: label_OR(x.loss, x.congestion), axis=1)\n",
    "# synth.to_csv('data/synth_latest.csv', header=True, encoding='utf-8')\n",
    "\n",
    "\n",
    "# raw['WMA'] = raw['rtt'].rolling(window=3, center=True, win_type ='triang').mean()\n",
    "# raw['WMA'].fillna(value=0, inplace=True)\n",
    "# raw['dist'] = raw.apply(lambda x: dist(x.rtt, x.WMA), axis=1)\n",
    "# raw['changepoint'] = raw['dist'].apply(lambda x: label_change(x))\n",
    "# del raw['WMA']\n",
    "# del raw['dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96b02063",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ewma = pd.Series.ewm\n",
    "plt.figure(figsize=(20, 5))\n",
    "# x = np.linspace(0, 2 * np.pi, 100)\n",
    "# y = 2 * np.sin(x) + 0.1 * np.random.normal(x)\n",
    "\n",
    "# master = raw\n",
    "master = synth\n",
    "\n",
    "# y = master['rtt'].reset_index(drop=True)\n",
    "# y = master['rtt'][:25000].reset_index(drop=True)\n",
    "y = master['rtt'] # entire dataset\n",
    "\n",
    "df = pd.Series(y)\n",
    "# take EWMA in both directions then average them\n",
    "\n",
    "SPAN = 20\n",
    "\n",
    "fwd = ewma(df, span=SPAN / 2).mean() # take EWMA in fwd direction\n",
    "bwd = ewma(df[::-1], span=SPAN).mean() # take EWMA in bwd direction\n",
    "\n",
    "# print(f\"fwd, bwd: {fwd}, {bwd}\")\n",
    "\n",
    "filtered = np.vstack(( fwd, bwd[::-1] )) # lump fwd and bwd together\n",
    "filtered = np.mean(filtered, axis=0 ) # average\n",
    "\n",
    "plt.plot(y, color = 'orange', alpha=.33) # raw data\n",
    "plt.plot(filtered, color='green', alpha=0.33) # combined ewma's\n",
    "plt.plot(fwd, color='red', alpha=0.1) # forward ewma\n",
    "plt.plot(bwd, color='blue', alpha=0.1) # bwd ewma\n",
    "\n",
    "diff = np.array(fwd) - np.array(bwd) # \n",
    "dist = np.square(diff)\n",
    "# print(np.round(dist, 2))\n",
    "plt.plot(dist, color='purple', alpha=1)\n",
    "\n",
    "# plt.ylim(top=250, bottom=-10)\n",
    "\n",
    "plt.xlabel('Measurement Index')\n",
    "plt.ylabel('RTT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d2f74",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save dist in dataset for current use\n",
    "def new_changept(ewma_dist, client_id):\n",
    "    global medians\n",
    "    THRESHOLD = medians[client_id]\n",
    "    if ewma_dist > THRESHOLD:\n",
    "        return VOTE\n",
    "    else:\n",
    "        return NORMAL\n",
    "    \n",
    "# ripe['ewma_dist'] = np.round(dist, 2)\n",
    "# ripe['changepoint'] = ripe.apply(lambda x: new_changept(x.ewma_dist), axis=1)\n",
    "tmp = ripe[:25000 * 5]\n",
    "\n",
    "# raw['ewma_dist'] = np.round(dist, 2)\n",
    "# tmp = raw[:5000]\n",
    "\n",
    "# tmp['changepoint'] = tmp.apply(lambda x: new_changept(x.ewma_dist, int(x.id)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68edebd",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ripe[ripe['id'] == 0].head(20)\n",
    "\n",
    "# tmp['ewma_dist']\n",
    "\n",
    "medians = []\n",
    "for i in range(10):\n",
    "#     medians.append(int(tmp[tmp['id'] == i]['ewma_dist'].median().round()))\n",
    "#     medians.append(int(tmp[tmp['id'] == i]['ewma_dist'].quantile(0.33).round())) # too many positive results\n",
    "#     medians.append(int(tmp[tmp['id'] == i]['ewma_dist'].quantile(0.45).round())) # all positives\n",
    "#     medians.append(int(tmp[tmp['id'] == i]['ewma_dist'].quantile(0.55).round())) # all false\n",
    "    medians.append(int(tmp[tmp['id'] == i]['ewma_dist'].quantile(0.49).round())) \n",
    "medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b98e1",
   "metadata": {},
   "source": [
    "### Here, we develop two network queries using logical operations between previously implemented tasks. \n",
    "We conduct these queries using combined labeling functions, which conduct lookups on the preexisting labels and label their values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52bb16",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def query1(x):\n",
    "    return (x.noise or x.changepoint or x.loss)\n",
    "\n",
    "def query2(x):\n",
    "    return (x.noise or x.changepoint or x.congestion)\n",
    "\n",
    "\"\"\" Apply Query 1 Labeling function. \"\"\"\n",
    "synth['query1'] = synth.apply(lambda x: query1(x), axis=1)\n",
    "synth['query2'] = synth.apply(lambda x: query2(x), axis=1)\n",
    "\n",
    "# raw['query1'] = raw.apply(lambda x: query1(x), axis=1)\n",
    "# raw['query2'] = raw.apply(lambda x: query2(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0b2c1",
   "metadata": {},
   "source": [
    "#### Now, develop test/training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "governmental-oxygen",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" First, define global tasks to create dataloaders for. \"\"\"\n",
    "# tasks = [\"loss\", \"congestion\", \"noise\"]\n",
    "tasks = [\"loss\", \"congestion\", \"noise\", \"changepoint\"]\n",
    "# tasks = [\"loss\", \"congestion\", \"noise\", \"changepoint\", \"query1\", \"query2\"]\n",
    "\n",
    "# X values are the measurements (rtt), Y values are the associated labels\n",
    "X_train, X_validate, X_test = {}, {}, {}\n",
    "Y_train, Y_validate, Y_test = {}, {}, {}\n",
    "\n",
    "\"\"\" Uncomment to use the CAIDA Data \"\"\"\n",
    "dataframe = synth  # synthetic CAIDA data\n",
    "test_set = raw\n",
    "num_entries = 28 # 28 entries in CAIDA Ark Dataset\n",
    "\n",
    "# dataframe = tmp\n",
    "# test_set = tmp\n",
    "num_entries = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff4c28b0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>i</th>\n",
       "      <th>rtt</th>\n",
       "      <th>loss</th>\n",
       "      <th>congestion</th>\n",
       "      <th>noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>724.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>559.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32.005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>616.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>565.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32.008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>666.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>27.533</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>32.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>619.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>25.089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>40.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>632.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>23.075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301406</th>\n",
       "      <td>27</td>\n",
       "      <td>2871</td>\n",
       "      <td>41.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301407</th>\n",
       "      <td>27</td>\n",
       "      <td>2871</td>\n",
       "      <td>606.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301408</th>\n",
       "      <td>27</td>\n",
       "      <td>2872</td>\n",
       "      <td>31.659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301409</th>\n",
       "      <td>27</td>\n",
       "      <td>2872</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301410</th>\n",
       "      <td>27</td>\n",
       "      <td>2872</td>\n",
       "      <td>50.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301411</th>\n",
       "      <td>27</td>\n",
       "      <td>2872</td>\n",
       "      <td>607.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301412</th>\n",
       "      <td>27</td>\n",
       "      <td>2873</td>\n",
       "      <td>29.030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301413</th>\n",
       "      <td>27</td>\n",
       "      <td>2873</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301414</th>\n",
       "      <td>27</td>\n",
       "      <td>2873</td>\n",
       "      <td>36.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301415</th>\n",
       "      <td>27</td>\n",
       "      <td>2873</td>\n",
       "      <td>652.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301416</th>\n",
       "      <td>27</td>\n",
       "      <td>2874</td>\n",
       "      <td>29.648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301417</th>\n",
       "      <td>27</td>\n",
       "      <td>2874</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301418</th>\n",
       "      <td>27</td>\n",
       "      <td>2874</td>\n",
       "      <td>37.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301419</th>\n",
       "      <td>27</td>\n",
       "      <td>2874</td>\n",
       "      <td>718.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301420</th>\n",
       "      <td>27</td>\n",
       "      <td>2875</td>\n",
       "      <td>29.737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301421</th>\n",
       "      <td>27</td>\n",
       "      <td>2875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301422</th>\n",
       "      <td>27</td>\n",
       "      <td>2875</td>\n",
       "      <td>37.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301423</th>\n",
       "      <td>27</td>\n",
       "      <td>2875</td>\n",
       "      <td>557.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301424</th>\n",
       "      <td>27</td>\n",
       "      <td>2876</td>\n",
       "      <td>37.092</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301425</th>\n",
       "      <td>27</td>\n",
       "      <td>2876</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301426</th>\n",
       "      <td>27</td>\n",
       "      <td>2876</td>\n",
       "      <td>49.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301427</th>\n",
       "      <td>27</td>\n",
       "      <td>2876</td>\n",
       "      <td>597.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301428</th>\n",
       "      <td>27</td>\n",
       "      <td>2877</td>\n",
       "      <td>28.937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301429</th>\n",
       "      <td>27</td>\n",
       "      <td>2877</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301430</th>\n",
       "      <td>27</td>\n",
       "      <td>2877</td>\n",
       "      <td>48.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301431</th>\n",
       "      <td>27</td>\n",
       "      <td>2877</td>\n",
       "      <td>656.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301432</th>\n",
       "      <td>27</td>\n",
       "      <td>2878</td>\n",
       "      <td>30.681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301433</th>\n",
       "      <td>27</td>\n",
       "      <td>2878</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301434</th>\n",
       "      <td>27</td>\n",
       "      <td>2878</td>\n",
       "      <td>50.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301435</th>\n",
       "      <td>27</td>\n",
       "      <td>2878</td>\n",
       "      <td>711.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301436 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     i      rtt  loss  congestion  noise\n",
       "0        0     0   29.445     0           0      0\n",
       "1        0     0    0.000     1           0      0\n",
       "2        0     0   36.000     0           1      0\n",
       "3        0     0  724.000     0           0      1\n",
       "4        0     1   29.688     0           0      0\n",
       "...     ..   ...      ...   ...         ...    ...\n",
       "301431  27  2877  656.000     0           0      1\n",
       "301432  27  2878   30.681     0           0      0\n",
       "301433  27  2878    0.000     1           0      0\n",
       "301434  27  2878   50.000     0           1      0\n",
       "301435  27  2878  711.000     0           0      1\n",
       "\n",
       "[301436 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af4f303d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'changepoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/arise/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2890\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'changepoint'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2947/3567146354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplt_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rtt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mY_validate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplt_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/arise/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2973\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/arise/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2890\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2892\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2893\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'changepoint'"
     ]
    }
   ],
   "source": [
    "# Only use augmented data for training; use raw data for testing\n",
    "for i in range(num_entries):\n",
    "    global dataframe\n",
    "    master = get(dataframe, index=i)\n",
    "    test = get(test_set, index=i)\n",
    "    \n",
    "    for task in tasks:\n",
    "        splt = split_df(master)\n",
    "#         print(splt)\n",
    "#         splt_2 = split_df(test_set, ct=4)\n",
    "        splt_2 = split_df(dataframe, ct=4)\n",
    "        splt_2 = splt_2[1].append(splt_2[2], ignore_index=True)\n",
    "\n",
    "        X_train[task] = splt[0]['rtt'].apply(lambda x : np.array([x]))\n",
    "        X_validate[task] = splt[1]['rtt'].apply(lambda x : np.array([x]))\n",
    "#         print((splt_2.head()))\n",
    "        X_test[task] = splt_2['rtt'].apply(lambda x : np.array([x]))\n",
    "\n",
    "        Y_train[task] = splt[0][task]\n",
    "        Y_validate[task] = splt[1][task]\n",
    "        Y_test[task] = splt_2[task]\n",
    "\n",
    "rtts = master['rtt'].apply(lambda x : np.array([x])) # convert rtt's into np array of sample arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70eaada8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tensors = X_train['changepoint']\n",
    "\n",
    "# print(X_train['changepoint'], type(X_train['changepoint']))\n",
    "\n",
    "# torch_tensor = torch.tensor(X_train['changepoint'])\n",
    "# print(torch_tensor)\n",
    "\n",
    "# head = ripe[ripe['id'] == 0].round(decimals=2)\n",
    "# print(head)\n",
    "# tensor = (torch.tensor(ripe[ripe['id'] == 0].values)).long()\n",
    "# print(tensor.shape)\n",
    "\n",
    "\n",
    "\n",
    "# print(X_train_tensors.shape)\n",
    "\n",
    "# X_train_tensors_final = torch.reshape(\n",
    "#                             X_train_tensors, \n",
    "#                             (\n",
    "#                                 X_train_tensors.shape[0], \n",
    "#                                 1, \n",
    "#                                 X_train_tensors.shape[1]\n",
    "#                             )\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-tennis",
   "metadata": {},
   "source": [
    "________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22518e65",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from snorkel.classification import DictDataset, DictDataLoader, Operation, Task, MultitaskClassifier, Trainer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from snorkel.analysis import Scorer\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "METRICS = [\"f1\"]\n",
    "LOSS_FUNC = F.cross_entropy\n",
    "# LOSS_FUNC = F.binary_cross_entropy\n",
    "SCORES = {}\n",
    "\n",
    "def train_and_evaluate(df, i : int, tasks : list, show_conf_matrix=False, n_epochs=10, lr=0.01, directory=\"\", savefig=False, \\\n",
    "                       cache_model=True, titleprefix=\"\", show_progress=False, model_name=\"MTL_Latest\", \\\n",
    "                       use_cached=False, time_override=False):\n",
    "    \"\"\" Iteratively train and evaluate the ith synthesized dataset. Results are stored in the SCORES dictionary, rather \n",
    "        than being returned. \"\"\"\n",
    "    global SCORES, METRICS, LOSS_FUNC, SEED\n",
    "    CACHE_DIR = \"./cache/\"\n",
    "    \n",
    "    X_train, X_validate, X_test = {}, {}, {}\n",
    "    Y_train, Y_validate, Y_test = {}, {}, {}\n",
    "    \n",
    "    master = get(df, index=i)\n",
    "    for task in tasks:\n",
    "        splt = split_df(master)\n",
    "        splt_2 = split_df(master, ct=4)\n",
    "        splt_2 = splt_2[1].append(splt_2[2], ignore_index=True)\n",
    "\n",
    "        X_train[task] = splt[0]['rtt'].apply(lambda x : np.array([x]))\n",
    "        X_validate[task] = splt[1]['rtt'].apply(lambda x : np.array([x]))\n",
    "        X_test[task] = splt_2['rtt'].apply(lambda x : np.array([x]))\n",
    "\n",
    "        Y_train[task] = splt[0][task]\n",
    "        Y_validate[task] = splt[1][task]\n",
    "        Y_test[task] = splt_2[task]\n",
    "\n",
    "        # new_df = pd.DataFrame()\n",
    "        # new_df['rtt'] = splt[0]['rtt'] # first tensor value is RTT\n",
    "        # new_df['datetime'] = splt[0]['datetime'] # second is datetime\n",
    "        # new_df['seq_len'] = 32\n",
    "        # # new_df[task] = splt[0][task] # assign 3rd tensor value to ground truth label\n",
    "        \n",
    "        # tensor = torch.LongTensor(new_df.values)\n",
    "        # print(tensor)\n",
    "        # X_train[task] = tensor\n",
    "        \n",
    "        # new_df = pd.DataFrame()\n",
    "        # new_df['rtt'] = splt[1]['rtt'] # first tensor value is RTT\n",
    "        # new_df['datetime'] = splt[1]['datetime'] # second is datetime\n",
    "        # X_validate[task] = torch.LongTensor(new_df.values)\n",
    "        \n",
    "        # new_df = pd.DataFrame()\n",
    "        # new_df['rtt'] = splt_2['rtt'] # first tensor value is RTT\n",
    "        # new_df['datetime'] = splt_2['datetime'] # second is datetime\n",
    "        # X_test[task] = torch.LongTensor(new_df.values)\n",
    "\n",
    "        Y_train[task] = splt[0][task]\n",
    "        Y_validate[task] = splt[1][task]\n",
    "        Y_test[task] = splt_2[task]\n",
    "        \n",
    "        \n",
    "    rtts = master['rtt'].apply(lambda x : np.array([x])) # convert rtt's into np array of sample arrays\n",
    "\n",
    "\n",
    "    \"\"\" Now, we define the dataloaders for the model. These will access the input data dictionaries for each\n",
    "        individual dataset and load the required portions needed for validation, training, and testing evaluations. \"\"\"\n",
    "    \n",
    "    loaders = {t : [] for t in [\"train\", \"valid\", \"test\"] + tasks} # used for confusion matrix generation\n",
    "    dataloaders = []\n",
    "    \n",
    "    for task_name in tasks:\n",
    "        for split, X, Y in (\n",
    "                (\"train\", X_train, Y_train),\n",
    "                (\"valid\", X_validate, Y_validate),\n",
    "                (\"test\", X_test, Y_test),\n",
    "            ):\n",
    "            \n",
    "            X_dict = {f\"{task_name}_data\": torch.FloatTensor(X[task_name])}\n",
    "            # X_dict = {f\"{task_name}_data\": torch.LongTensor(X[task_name])}\n",
    "            # print(X_dict)\n",
    "    \n",
    "            Y_dict = {f\"{task_name}_task\": torch.LongTensor(Y[task_name])}\n",
    "            \n",
    "            dataset = DictDataset(f\"{task_name}_Dataset\", split, X_dict, Y_dict)\n",
    "            dataloader = DictDataLoader(dataset, batch_size=32) # batch size is the number of data points loaded in at time\n",
    "            dataloaders.append(dataloader)\n",
    "\n",
    "            loaders[split].append(dataloader)     # add current loader to list sorted by data type (test, train, or val)\n",
    "            loaders[task_name].append(dataloader) # add current loader based on task\n",
    "    \n",
    "    \n",
    "    \"\"\" Here, we define the initial layers of the perceptron model. 'base_mlp' indicates the layer shared between the \n",
    "        different tasks, while the 'head_module' denotes the model's prediction layer. \"\"\"\n",
    "\n",
    "    # Define a two-layer MLP module and a one-layer prediction \"head\" module\n",
    "    # base_mlp = nn.Sequential(nn.Linear(2, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU())\n",
    "    \n",
    "    numLayers = 4 # default 4\n",
    "    hiddenSize = 4 # default 4\n",
    "    in_features = 1\n",
    "    \n",
    "    base_mlp = nn.Sequential(\n",
    "                    # nn.LSTM(in_features, hidden_size=hiddenSize, num_layers=1, bidirectional=True),\n",
    "                    # nn.ReLU(),\n",
    "                    nn.Linear(in_features, hiddenSize), \n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hiddenSize, 4), \n",
    "                    nn.ReLU()\n",
    "                )\n",
    "    \n",
    "    # head_module = nn.Linear(4, 2)\n",
    "    # # The module pool contains all the modules this task uses\n",
    "    # module_pool = nn.ModuleDict({\"base_mlp\": base_mlp, \"loss_head_module\": head_module})\n",
    "\n",
    "    # # From the input dictionary, pull out 'loss_data' and send it through input_module\n",
    "    # op1 = Operation( name=\"base_mlp\", module_name=\"base_mlp\", inputs=[(\"_input_\", \"loss_data\")] )\n",
    "    # # Pass the output of op1 (the MLP module) as input to the head_module\n",
    "    # op2 = Operation( name=\"loss_head\", module_name=\"loss_head_module\", inputs=[\"base_mlp\"] )\n",
    "    # op_sequence = [op1, op2]\n",
    "    \n",
    "    \n",
    "    def initialize_task(taskname : str, base):\n",
    "        \"\"\" A more modular method of defining the same tasks as seen above. \"\"\"\n",
    "        global LOSS_FUNC, METRICS\n",
    "        \n",
    "        in_features = 4  # number of elements in hidden layer\n",
    "        out_features = 2\n",
    "        \n",
    "        task = Task(\n",
    "            name = f\"{taskname}_task\",\n",
    "            module_pool = nn.ModuleDict({\"base_mlp\": base, f\"{taskname}_head\": nn.Linear(in_features, out_features)}),\n",
    "            loss_func = LOSS_FUNC,\n",
    "            output_func = partial(F.softmax, dim=1),\n",
    "            scorer = Scorer(metrics=METRICS),\n",
    "            op_sequence = [\n",
    "                    Operation(\"base_mlp\", [(\"_input_\", f\"{taskname}_data\")]), # base multi-layered perception\n",
    "                    Operation(f\"{taskname}_head\", [\"base_mlp\"]),\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        return task\n",
    "    \n",
    "#     loss_task = initialize_task(\"loss\", base_mlp)\n",
    "#     noise_task = initialize_task(\"noise\", base_mlp)\n",
    "#     congestion_task = initialize_task(\"congestion\", base_mlp)\n",
    "#     changepoint_task = initialize_task(\"changepoint\", base_mlp)\n",
    "#     ddos_task = initialize_task(\"ddos\", base_mlp)\n",
    "    \n",
    "    TASKS = [initialize_task(t, base_mlp) for t in tasks]\n",
    "        \n",
    "    # TASKS = [loss_task, noise_task, congestion_task] # original tasks\n",
    "    # TASKS = [loss_task, noise_task, congestion_task, changepoint_task]\n",
    "    # TASKS = [loss_task, noise_task, congestion_task, changepoint_task, ddos_task]\n",
    "    \n",
    "    \"\"\" Finally, we train the Multi Task classifier and score it according to our evaluation metrics list described above. \n",
    "        By default, we use the model's F1 score as the basis for evaluation. The duration of the training process for each \n",
    "        individual dataset within the model is also recorded. \"\"\"\n",
    "    \n",
    "    # model = MultitaskClassifier(TASKS)\n",
    "    model = MultitaskClassifier(TASKS, device=CUDA_INDEX) # use GPU device if available\n",
    "    \n",
    "    if torch.cuda.is_available() and CUDA_INDEX >= 0:\n",
    "        model.to(f'cuda:{CUDA_INDEX}') # load to GPU if available\n",
    "    \n",
    "    trainer_config = { # see https://github.com/snorkel-team/snorkel/blob/master/snorkel/classification/training/trainer.py\n",
    "        \"seed\": SEED,\n",
    "        \"n_epochs\": n_epochs, \n",
    "        \"lr\": lr,\n",
    "        \"lr_scheduler\": \"linear\", # one of [\"constant\", \"linear\", \"exponential\", \"step\"]\n",
    "        \"progress_bar\": show_progress,\n",
    "        \"checkpointing\": True\n",
    "    }\n",
    "    trainer = Trainer(**trainer_config)\n",
    "    \n",
    "    if use_cached:\n",
    "        try:\n",
    "            model.load(CACHE_DIR + model_name)\n",
    "        except:\n",
    "            use_cached = False # if we fail to load config, simply regen model config\n",
    "            print(f\"Error loading cached model {model_name}\")\n",
    "    \n",
    "    \n",
    "    start = timer() # get current time for measurement analysis    \n",
    "    trainer.fit(model, dataloaders)\n",
    "    end = timer()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    results = model.score(dataloaders, as_dataframe=False)\n",
    "    # print(model.eval())\n",
    "    # print('model.score:', results)\n",
    "    \n",
    "    try:\n",
    "        if time_override:\n",
    "            assert False\n",
    "        if \"Time\" in SCORES[i].keys(): # if this is a second iteration:\n",
    "            SCORES[i][\"Time\"] = round(SCORES[i][\"Time\"] + round(end - start, 5), 5)\n",
    "            SCORES[i][\"Scores\"] = results\n",
    "            SCORES[i][\"Iterations\"] += 1\n",
    "    except:\n",
    "        SCORES[i] = {\"Time\": round(end - start, 5), \"Scores\": results, \"Index\": i, \"Iterations\": 0}\n",
    "        \n",
    "\n",
    "    \"\"\"  Cache MTL Model to specified filepath: \"\"\"\n",
    "    \n",
    "    if cache_model:\n",
    "        model.save(CACHE_DIR + model_name)\n",
    "    \n",
    "        \n",
    "    \"\"\" Generating Confusion Matrices: \"\"\"    \n",
    "\n",
    "    typ = \"test\" # test, train, or valid; which set of the data should be used to generate the confusion matrices?\n",
    "    result_list = []\n",
    "    \n",
    "    for dl in loaders[typ]:\n",
    "        res = model.predict(dl, return_preds=True)\n",
    "        result_list.append(res)\n",
    "\n",
    "        # print('model.predict:', res)\n",
    "        # print(res['preds'].keys())\n",
    "        \n",
    "        key = list(res['preds'].keys())[0]\n",
    "\n",
    "        preds = res[\"preds\"][f\"{key}\"] # predictions\n",
    "        \n",
    "        try:\n",
    "            if show_conf_matrix:\n",
    "                weak_labels = dl.dataset.Y_dict[f\"{key}\"].numpy() # convert tensor to np array\n",
    "                conf = gen_confusion_matrix(preds, weak_labels, index=f\"{i:02d}\", filetype=\"png\", save=savefig, \\\n",
    "                                     selected_feature=key.split('_')[0], pre=titleprefix, useTitle=True, folder=directory)\n",
    "        except:\n",
    "            print(f\"Error drawing confusion matrix for {i:02d}: {key}\")\n",
    "            pass\n",
    "    \n",
    "    \"\"\" Printing hidden model layers. \"\"\"\n",
    "    # l = [module for module in model.modules() if not isinstance(module, nn.Sequential)]\n",
    "    # print(l)\n",
    "\n",
    "    # print(list(model.modules()))\n",
    "    \n",
    "    # print(\"=\" * 50)\n",
    "    # print(f\"model: {model}\")\n",
    "    # print(dir(model))\n",
    "    # print(model.modules)\n",
    "    # print(model.add_module)\n",
    "    # print(model.add_task)\n",
    "    \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-sector",
   "metadata": {},
   "source": [
    "### Now that all the helper functions are defined, it's time to train the model.  \n",
    "We do this by calling the `train_and_evaluate()` function defined above. The `sets` parameter is a `list`-like object containing the indices of the datasets to train and evaluate the model on. To train on all 28 datasets, `sets` should contain indices `0..27`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d43ed364",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training on dataset 00 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:: 100%|██████████| 507/507 [00:04<00:00, 125.82it/s, model/all/train/loss=21, model/all/train/lr=8e-5, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.526, congestion_task/congestion_Dataset/valid/f1=0.566]\n",
      "Epoch 1:: 100%|██████████| 507/507 [00:02<00:00, 183.87it/s, model/all/train/loss=12.2, model/all/train/lr=6e-5, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.526, congestion_task/congestion_Dataset/valid/f1=0.566]   \n",
      "Epoch 2:: 100%|██████████| 507/507 [00:02<00:00, 183.77it/s, model/all/train/loss=5.6, model/all/train/lr=4e-5, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.528, congestion_task/congestion_Dataset/valid/f1=0.566]    \n",
      "Epoch 3:: 100%|██████████| 507/507 [00:02<00:00, 183.36it/s, model/all/train/loss=1.54, model/all/train/lr=2e-5, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0]       \n",
      "Epoch 4:: 100%|██████████| 507/507 [00:02<00:00, 174.64it/s, model/all/train/loss=0.372, model/all/train/lr=0, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.994, congestion_task/congestion_Dataset/valid/f1=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'Index': 0,\n",
      "     'Iterations': 0,\n",
      "     'Scores': {'congestion_task/congestion_Dataset/test/f1': 0.0,\n",
      "                'congestion_task/congestion_Dataset/train/f1': 0.0,\n",
      "                'congestion_task/congestion_Dataset/valid/f1': 0.0,\n",
      "                'loss_task/loss_Dataset/test/f1': 1.0,\n",
      "                'loss_task/loss_Dataset/train/f1': 1.0,\n",
      "                'loss_task/loss_Dataset/valid/f1': 1.0,\n",
      "                'noise_task/noise_Dataset/test/f1': 0.9917127071823205,\n",
      "                'noise_task/noise_Dataset/train/f1': 0.9916394038531443,\n",
      "                'noise_task/noise_Dataset/valid/f1': 0.994417306350314},\n",
      "     'Time': 15.25767}}\n",
      "\n",
      "Mean F1 score: `0.6641966019317531`  \n",
      "Total time: `15.25767` seconds.\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "SCORES = {}\n",
    "\n",
    "# CAIDA Presets\n",
    "# sets = range(28)    # train on all 28 datasets\n",
    "# sets = [11, 15, 26] # train only on a specific subset of the datasets\n",
    "sets = range(1)\n",
    "\n",
    "# results = {}\n",
    "\n",
    "rates = [0.01] # learning rates to try\n",
    "rates = [0.0001] # naive learning rates\n",
    "avgs = []\n",
    "\n",
    "# tasks = [\"loss\", \"noise\", \"congestion\", \"changepoint\", \"query1\", \"query2\"]\n",
    "# tasks = [\"loss\", \"noise\", \"congestion\", \"changepoint\"]\n",
    "tasks = [\"loss\", \"noise\", \"congestion\"]\n",
    "# tasks = [\"changepoint\"]\n",
    "\n",
    "# tasks = [\"noise\", \"changepoint\", \"loss\", \"query1\"]\n",
    "# tasks = [\"noise\", \"changepoint\", \"query1\", \"query2\"]\n",
    "\n",
    "for rate in rates:\n",
    "#     SCORES = {}\n",
    "    for i in sets:\n",
    "        print(f\"{'='*5} Training on dataset {i:02d} {'='*5}\")\n",
    "\n",
    "        EPOCHS = 5\n",
    "    \n",
    "        cache = True # use cached model\n",
    "        cache = False\n",
    "        save_cache = False\n",
    "    \n",
    "        # CAIDA -- train on augmented, test on original/raw\n",
    "        results = train_and_evaluate(synth, i, tasks, savefig=False, show_conf_matrix=False, \\\n",
    "                                     n_epochs=EPOCHS, lr=rate, titleprefix=\"lr_\", cache_model=save_cache, \\\n",
    "                                     show_progress=True, use_cached=cache, model_name=f\"{i:02d}_MTL\")\n",
    "                        \n",
    "        # Raw CAIDA data\n",
    "        # results = train_and_evaluate(raw, i, tasks, savefig=False, show_conf_matrix=False, \\\n",
    "        #                              n_epochs=EPOCHS, lr=rate, titleprefix=\"raw_\", cache_model=save_cache, \\\n",
    "        #                              show_progress=True, use_cached=cache, model_name=f\"{i:02d}_MTL_raw\")\n",
    "\n",
    "    avg = 0\n",
    "    time = 0\n",
    "    pprint(SCORES)\n",
    "    \n",
    "    for i in SCORES:\n",
    "        for j in SCORES[i]['Scores']:\n",
    "            avg += SCORES[i]['Scores'][j] / len(SCORES[i]['Scores'])\n",
    "\n",
    "        time += SCORES[i][\"Time\"]\n",
    "\n",
    "    avg /= len(SCORES)\n",
    "    avgs.append(avg)\n",
    "    print(f\"\\nMean F1 score: `{avg}`  \")\n",
    "    print(f'Total time: `{round(time, 5)}` seconds.\\n')\n",
    "    \n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "small-glasgow",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SCORES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35248/1102637997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m# True to print result dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSCORES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if should print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'```  '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SCORES' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" Printing the initial scores: \"\"\"\n",
    "time = 0\n",
    "\n",
    "avg = 0 # average F1 score\n",
    "p = True # True to print result dictionary\n",
    "\n",
    "for i in SCORES:\n",
    "    if p: # if should print\n",
    "        print('```  ')\n",
    "        pprint(SCORES[i])\n",
    "        print('```  ')\n",
    "    \n",
    "    for j in SCORES[i]['Scores']:\n",
    "        avg += SCORES[i]['Scores'][j] / len(SCORES[i]['Scores'])\n",
    "        \n",
    "    time += SCORES[i][\"Time\"]\n",
    "\n",
    "avg /= len(SCORES)\n",
    "learningrate = \"Flexible, started at 0.01\"\n",
    "print(f\"\\nMean F1 score: `{avg}`  \")\n",
    "print(f\"Mean Time score: `{round(time / len(SCORES), 5)}` seconds  \")\n",
    "print(f'Total time: `{round(time, 5)}` seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-manor",
   "metadata": {},
   "source": [
    "___________  \n",
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "downtown-chapter",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Serialize results: \"\"\"\n",
    "prev_names = [\"min_0.90\", \"min_0.92\", \"synth_4x_raw\", \"synth_4x_reiterated_10x\", \"synth_4x_reiterated_7x\", \"gap500\", \\\n",
    "              \"gap500_noreiterate\", \"latest\", \"gap500_1x\", \"lr0015_initial\", \"lr0015_min95\"]\n",
    "\n",
    "# save(SCORES, \"lr_adaptive\")\n",
    "# save(SCORES, \"lr_adaptive_cont\")\n",
    "# save(SCORES, \"CAIDA_max\")\n",
    "\n",
    "# save(SCORES, \"CAIDA_scores\")\n",
    "# save(SCORES, \"CAIDA_retrain\")\n",
    "# save(SCORES, \"CAIDA_queries\")\n",
    "\n",
    "\"\"\" Load serialized results from root/MTL/data/ \"\"\"\n",
    "# saved_scores = load(\"CAIDA_max\")\n",
    "# saved_scores = load(\"CAIDA_scores\")\n",
    "# saved_scores = load(\"CAIDA_retrain\")\n",
    "# saved_scores = load(\"CAIDA_queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29180e58",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "### Combining result dicts:\n",
    "# old = load(\"CAIDA_retrain\")\n",
    "# for i in SCORES:\n",
    "#     old[i] = SCORES[i]\n",
    "# save(old, \"CAIDA_retrain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-vanilla",
   "metadata": {},
   "source": [
    "### If needed, we can re-train the models iteratively using a given number of retry attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6c6d682",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 00 -- congestion_task/congestion_Dataset/test/f1 == 0.0 < 0.5\n",
      "Dataset 02 -- congestion_task/congestion_Dataset/test/f1 == 0.0 < 0.5\n",
      "redos: [0, 2]\n"
     ]
    }
   ],
   "source": [
    "# SCORES = saved_scores\n",
    "\n",
    "def redo_list(redoThreshold):\n",
    "    global SCORES\n",
    "    redos = []\n",
    "    for j in SCORES.keys():\n",
    "        for s in SCORES[j]['Scores'].keys():\n",
    "            if \"test\" not in s:\n",
    "                continue # only care about test datasets\n",
    "\n",
    "            if SCORES[j]['Scores'][s] < redoThreshold:\n",
    "                if \"changepoint\" in s:\n",
    "                    changeThresh = 0.65\n",
    "                    if SCORES[j]['Scores'][s] < changeThresh:\n",
    "                        redos.append(j)\n",
    "                        print(f\"Dataset {j:02d} -- {s} == {SCORES[j]['Scores'][s]} < {changeThresh}\")\n",
    "                else:\n",
    "                    redos.append(j)\n",
    "                    print(f\"Dataset {j:02d} -- {s} == {SCORES[j]['Scores'][s]} < {redoThreshold}\")\n",
    "                break\n",
    "    return redos\n",
    "\n",
    "redos = redo_list(0.50)\n",
    "\n",
    "print(f\"redos: {redos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "therapeutic-karma",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Iteration 1 ----\n",
      "Dataset 00 -- congestion_task/congestion_Dataset/test/f1 == 0.0 < 0.9\n",
      "Dataset 02 -- congestion_task/congestion_Dataset/test/f1 == 0.0 < 0.9\n",
      "===== Re-Training on dataset 00 =====\n",
      "\n",
      "\n",
      "My Device: 0\t Config Device: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:: 100%|██████████| 676/676 [00:16<00:00, 41.58it/s, model/all/train/loss=0.524, model/all/train/lr=0.009, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.966, congestion_task/congestion_Dataset/valid/f1=0.75, changepoint_task/changepoint_Dataset/valid/f1=0.989]\n",
      "Epoch 1:: 100%|██████████| 676/676 [00:16<00:00, 42.07it/s, model/all/train/loss=0.102, model/all/train/lr=0.008, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.967, congestion_task/congestion_Dataset/valid/f1=0.755, changepoint_task/changepoint_Dataset/valid/f1=0.989]  \n",
      "Epoch 2:: 100%|██████████| 676/676 [00:14<00:00, 45.38it/s, model/all/train/loss=0.099, model/all/train/lr=0.007, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.984, congestion_task/congestion_Dataset/valid/f1=0.758, changepoint_task/changepoint_Dataset/valid/f1=0.989]   \n",
      "Epoch 3:: 100%|██████████| 676/676 [00:16<00:00, 40.95it/s, model/all/train/loss=0.0972, model/all/train/lr=0.006, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.991, congestion_task/congestion_Dataset/valid/f1=0.758, changepoint_task/changepoint_Dataset/valid/f1=0.989]  \n",
      "Epoch 4:: 100%|██████████| 676/676 [00:17<00:00, 39.04it/s, model/all/train/loss=0.0967, model/all/train/lr=0.005, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.994, congestion_task/congestion_Dataset/valid/f1=0.758, changepoint_task/changepoint_Dataset/valid/f1=0.989]  \n",
      "Epoch 5:: 100%|██████████| 676/676 [00:16<00:00, 40.95it/s, model/all/train/loss=0.0961, model/all/train/lr=0.004, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.994, congestion_task/congestion_Dataset/valid/f1=0.759, changepoint_task/changepoint_Dataset/valid/f1=0.989]  \n",
      "Epoch 6:: 100%|██████████| 676/676 [00:16<00:00, 41.66it/s, model/all/train/loss=0.0953, model/all/train/lr=0.003, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0.759, changepoint_task/changepoint_Dataset/valid/f1=0.989]  \n",
      "Epoch 7:: 100%|██████████| 676/676 [00:16<00:00, 41.03it/s, model/all/train/loss=0.0952, model/all/train/lr=0.002, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0.759, changepoint_task/changepoint_Dataset/valid/f1=0.989]  \n",
      "Epoch 8:: 100%|██████████| 676/676 [00:16<00:00, 40.97it/s, model/all/train/loss=0.0949, model/all/train/lr=0.001, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.997, congestion_task/congestion_Dataset/valid/f1=0.76, changepoint_task/changepoint_Dataset/valid/f1=0.989]   \n",
      "Epoch 9:: 100%|██████████| 676/676 [00:16<00:00, 41.13it/s, model/all/train/loss=0.0945, model/all/train/lr=0, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.997, congestion_task/congestion_Dataset/valid/f1=0.759, changepoint_task/changepoint_Dataset/valid/f1=0.989]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Re-Training on dataset 02 =====\n",
      "\n",
      "\n",
      "My Device: 0\t Config Device: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:: 100%|██████████| 636/636 [00:15<00:00, 41.06it/s, model/all/train/loss=0.624, model/all/train/lr=0.009, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.978, congestion_task/congestion_Dataset/valid/f1=0, changepoint_task/changepoint_Dataset/valid/f1=0.991]\n",
      "Epoch 1:: 100%|██████████| 636/636 [00:15<00:00, 42.39it/s, model/all/train/loss=0.164, model/all/train/lr=0.008, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.978, congestion_task/congestion_Dataset/valid/f1=0, changepoint_task/changepoint_Dataset/valid/f1=0.991]  \n",
      "Epoch 2:: 100%|██████████| 636/636 [00:15<00:00, 41.48it/s, model/all/train/loss=0.154, model/all/train/lr=0.007, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.991, congestion_task/congestion_Dataset/valid/f1=0, changepoint_task/changepoint_Dataset/valid/f1=0.991]  \n",
      "Epoch 3:: 100%|██████████| 636/636 [00:14<00:00, 42.55it/s, model/all/train/loss=0.112, model/all/train/lr=0.006, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.992, congestion_task/congestion_Dataset/valid/f1=0.759, changepoint_task/changepoint_Dataset/valid/f1=0.991]\n",
      "Epoch 4:: 100%|██████████| 636/636 [00:14<00:00, 44.34it/s, model/all/train/loss=0.0972, model/all/train/lr=0.005, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.993, congestion_task/congestion_Dataset/valid/f1=0.759, changepoint_task/changepoint_Dataset/valid/f1=0.991]  \n",
      "Epoch 5:: 100%|██████████| 636/636 [00:15<00:00, 41.35it/s, model/all/train/loss=0.0935, model/all/train/lr=0.004, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.992, congestion_task/congestion_Dataset/valid/f1=0.757, changepoint_task/changepoint_Dataset/valid/f1=0.991]  \n",
      "Epoch 6:: 100%|██████████| 636/636 [00:15<00:00, 41.75it/s, model/all/train/loss=0.0931, model/all/train/lr=0.003, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.994, congestion_task/congestion_Dataset/valid/f1=0.759, changepoint_task/changepoint_Dataset/valid/f1=0.991]  \n",
      "Epoch 7:: 100%|██████████| 636/636 [00:15<00:00, 41.51it/s, model/all/train/loss=0.0927, model/all/train/lr=0.002, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0.757, changepoint_task/changepoint_Dataset/valid/f1=0.991]  \n",
      "Epoch 8:: 100%|██████████| 636/636 [00:15<00:00, 41.58it/s, model/all/train/loss=0.0923, model/all/train/lr=0.001, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0.757, changepoint_task/changepoint_Dataset/valid/f1=0.991]  \n",
      "Epoch 9:: 100%|██████████| 636/636 [00:15<00:00, 41.81it/s, model/all/train/loss=0.0922, model/all/train/lr=0, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0.757, changepoint_task/changepoint_Dataset/valid/f1=0.991]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 00 -- congestion_task/congestion_Dataset/test/f1 == 0.7661194384963121 < 0.9\n",
      "Dataset 02 -- congestion_task/congestion_Dataset/test/f1 == 0.7525851197982346 < 0.9\n",
      "Models that need to be re-trained:\n",
      " [0, 2]\n",
      "\n",
      "---- Iteration 2 ----\n",
      "Dataset 00 -- congestion_task/congestion_Dataset/test/f1 == 0.7661194384963121 < 0.9\n",
      "Dataset 02 -- congestion_task/congestion_Dataset/test/f1 == 0.7525851197982346 < 0.9\n",
      "===== Re-Training on dataset 00 =====\n",
      "\n",
      "\n",
      "My Device: 0\t Config Device: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:: 100%|██████████| 676/676 [00:16<00:00, 41.26it/s, model/all/train/loss=0.66, model/all/train/lr=0.009, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.966, congestion_task/congestion_Dataset/valid/f1=0, changepoint_task/changepoint_Dataset/valid/f1=0.989]\n",
      "Epoch 1:: 100%|██████████| 676/676 [00:16<00:00, 41.17it/s, model/all/train/loss=0.195, model/all/train/lr=0.008, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.973, congestion_task/congestion_Dataset/valid/f1=0.566, changepoint_task/changepoint_Dataset/valid/f1=0.989]\n",
      "Epoch 2:: 100%|██████████| 676/676 [00:15<00:00, 44.50it/s, model/all/train/loss=0.113, model/all/train/lr=0.007, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.994, congestion_task/congestion_Dataset/valid/f1=0.828, changepoint_task/changepoint_Dataset/valid/f1=0.989]  \n",
      "Epoch 3:: 100%|██████████| 676/676 [00:16<00:00, 41.09it/s, model/all/train/loss=0.0668, model/all/train/lr=0.006, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0.951, changepoint_task/changepoint_Dataset/valid/f1=0.989]  \n",
      "Epoch 4:: 100%|██████████| 676/676 [00:16<00:00, 41.20it/s, model/all/train/loss=0.048, model/all/train/lr=0.005, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.997, congestion_task/congestion_Dataset/valid/f1=0.92, changepoint_task/changepoint_Dataset/valid/f1=0.989]    \n",
      "Epoch 5:: 100%|██████████| 676/676 [00:13<00:00, 51.25it/s, model/all/train/loss=0.0367, model/all/train/lr=0.004, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.997, congestion_task/congestion_Dataset/valid/f1=0.949, changepoint_task/changepoint_Dataset/valid/f1=0.989] \n",
      "Epoch 6:: 100%|██████████| 676/676 [00:14<00:00, 47.00it/s, model/all/train/loss=0.0311, model/all/train/lr=0.003, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.998, congestion_task/congestion_Dataset/valid/f1=0.982, changepoint_task/changepoint_Dataset/valid/f1=0.989]  \n",
      "Epoch 7:: 100%|██████████| 676/676 [00:16<00:00, 41.21it/s, model/all/train/loss=0.0272, model/all/train/lr=0.002, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.998, congestion_task/congestion_Dataset/valid/f1=0.984, changepoint_task/changepoint_Dataset/valid/f1=0.989]  \n",
      "Epoch 8:: 100%|██████████| 676/676 [00:15<00:00, 44.04it/s, model/all/train/loss=0.0251, model/all/train/lr=0.001, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.998, congestion_task/congestion_Dataset/valid/f1=0.99, changepoint_task/changepoint_Dataset/valid/f1=0.989]   \n",
      "Epoch 9:: 100%|██████████| 676/676 [00:16<00:00, 41.43it/s, model/all/train/loss=0.0234, model/all/train/lr=0, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.999, congestion_task/congestion_Dataset/valid/f1=0.985, changepoint_task/changepoint_Dataset/valid/f1=0.989]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Re-Training on dataset 02 =====\n",
      "\n",
      "\n",
      "My Device: 0\t Config Device: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:: 100%|██████████| 636/636 [00:15<00:00, 41.24it/s, model/all/train/loss=0.258, model/all/train/lr=0.009, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.00148, congestion_task/congestion_Dataset/valid/f1=0.754, changepoint_task/changepoint_Dataset/valid/f1=0.991]\n",
      "Epoch 1:: 100%|██████████| 636/636 [00:15<00:00, 41.06it/s, model/all/train/loss=0.0973, model/all/train/lr=0.008, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.97, congestion_task/congestion_Dataset/valid/f1=0.853, changepoint_task/changepoint_Dataset/valid/f1=0.991]     \n",
      "Epoch 2:: 100%|██████████| 636/636 [00:15<00:00, 41.27it/s, model/all/train/loss=0.0844, model/all/train/lr=0.007, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.979, congestion_task/congestion_Dataset/valid/f1=0.758, changepoint_task/changepoint_Dataset/valid/f1=0.991] \n",
      "Epoch 3:: 100%|██████████| 636/636 [00:15<00:00, 41.09it/s, model/all/train/loss=0.0987, model/all/train/lr=0.006, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.99, congestion_task/congestion_Dataset/valid/f1=0.759, changepoint_task/changepoint_Dataset/valid/f1=0.991]   \n",
      "Epoch 4:: 100%|██████████| 636/636 [00:15<00:00, 41.96it/s, model/all/train/loss=0.0948, model/all/train/lr=0.005, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.991, congestion_task/congestion_Dataset/valid/f1=0.757, changepoint_task/changepoint_Dataset/valid/f1=0.991] \n",
      "Epoch 5:: 100%|██████████| 636/636 [00:15<00:00, 41.94it/s, model/all/train/loss=0.0842, model/all/train/lr=0.004, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0.843, changepoint_task/changepoint_Dataset/valid/f1=0.991]  \n",
      "Epoch 6:: 100%|██████████| 636/636 [00:14<00:00, 43.11it/s, model/all/train/loss=0.0475, model/all/train/lr=0.003, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0.819, changepoint_task/changepoint_Dataset/valid/f1=0.991]  \n",
      "Epoch 7:: 100%|██████████| 636/636 [00:15<00:00, 41.72it/s, model/all/train/loss=0.0358, model/all/train/lr=0.002, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0.927, changepoint_task/changepoint_Dataset/valid/f1=0.991]  \n",
      "Epoch 8:: 100%|██████████| 636/636 [00:15<00:00, 41.88it/s, model/all/train/loss=0.026, model/all/train/lr=0.001, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.995, congestion_task/congestion_Dataset/valid/f1=0.952, changepoint_task/changepoint_Dataset/valid/f1=0.991]   \n",
      "Epoch 9:: 100%|██████████| 636/636 [00:15<00:00, 40.98it/s, model/all/train/loss=0.0234, model/all/train/lr=0, loss_task/loss_Dataset/valid/f1=1, noise_task/noise_Dataset/valid/f1=0.994, congestion_task/congestion_Dataset/valid/f1=0.963, changepoint_task/changepoint_Dataset/valid/f1=0.991]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models that need to be re-trained:\n",
      " []\n",
      "\n",
      "---- Iteration 3 ----\n",
      "Model satisfactorily trained after 3 iterations.\n"
     ]
    }
   ],
   "source": [
    "# SCORES = load('synth_4x_reiterated_7x')\n",
    "# SCORES = load('latest')\n",
    "# SCORES = load(\"lr_adaptive\")\n",
    "\n",
    "attempts = 5 # number of times to try again if model scores are less than desired.\n",
    "redoThreshold = 0.90 # any score less than this indicates the model needs to be re-trained\n",
    "\n",
    "# df = master\n",
    "df = synth\n",
    "# df = ripe\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "RATE = 0.01\n",
    "\n",
    "for i in range(attempts):\n",
    "    print('-'*4, f\"Iteration {i + 1}\", '-'*4)\n",
    "    \n",
    "    redos = redo_list(redoThreshold)\n",
    "    \n",
    "    for j in redos:\n",
    "        print(f\"{'='*5} Re-Training on dataset {j:02d} {'='*5}\")\n",
    "\n",
    "        if (df.equals(synth)): # Synthetic\n",
    "            results = train_and_evaluate(df, j, tasks, savefig=False, show_conf_matrix=False, cache_model=True, \\\n",
    "                                         n_epochs=EPOCHS, lr=rate, titleprefix=\"caida_\", time_override=True, \\\n",
    "                                         show_progress=True, use_cached=False, model_name=f\"CAIDA_{i:02d}\")\n",
    "        # RIPE Atlas\n",
    "        elif (df.equals(ripe)):\n",
    "            results = train_and_evaluate(df, j, tasks, savefig=False, show_conf_matrix=True, time_override=True, \\\n",
    "                                         n_epochs=EPOCHS, lr=rate, titleprefix=\"ripe_\", cache_model=True, \\\n",
    "                                         show_progress=True, use_cached=False, model_name=f\"RIPE_{i:02d}_MTL\", \\\n",
    "                                         directory=\"ripe\")\n",
    "    \n",
    "    if redos == []:\n",
    "        print(f\"Model satisfactorily trained after {i + 1} iterations.\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Models that need to be re-trained:\\n\", redo_list(redoThreshold))\n",
    "    \n",
    "    if i == attempts - 1:\n",
    "        print(\"Iteration attempts exceeded.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-launch",
   "metadata": {},
   "source": [
    "### Lastly, we analyze and print the average scores and training times for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "grateful-sewing",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save(SCORES, \"ripe\")\n",
    "# save(SCORES, \"ripe_changepoint\")\n",
    "# save(SCORES, \"ripe_all\")\n",
    "\n",
    "# save(SCORES, \"CAIDA_max\")\n",
    "# save(SCORES, \"CAIDA_scores\")\n",
    "# save(SCORES, \"CAIDA_retrain\")\n",
    "# save(SCORES, \"CAIDA_queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "experienced-situation",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test score for loss \t: `1.0`  \n",
      "mean test score for noise \t: `0.995567`  \n",
      "mean test score for congestion \t: `0.97134`  \n",
      "mean test score for changepoint \t: `0.990527`  \n",
      "\n",
      "Mean time to train to F1 score ≥ 0.96:   `164.05881` seconds, stdev: `16.31631`s  \n",
      "Total time: `492.17642` seconds.  \n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, stdev\n",
    "\n",
    "congestion_scores = []\n",
    "loss_scores       = []\n",
    "noise_scores      = []\n",
    "times             = []\n",
    "\n",
    "saved_scores = SCORES\n",
    "# del saved_scores[11]\n",
    "# print(saved_scores[11])\n",
    "# saved_scores = load(\"synth_4x_reiterated_7x\")\n",
    "\n",
    "min_score = 1.0\n",
    "for k in list(saved_scores[list(saved_scores.keys())[0]]['Scores'].keys()):\n",
    "    # For each key in the 'Scores' dict...\n",
    "    if \"test\" not in k:\n",
    "        continue # only use 'test' scores\n",
    "    \n",
    "    current = [saved_scores[j]['Scores'][k] for j in saved_scores.keys()]\n",
    "    \n",
    "    c_min = min([c for c in current if c != 0]) # ignore 0.0s when mentioning min score\n",
    "#     c_min = min(current)\n",
    "    \n",
    "    min_score = min(c_min, min_score)\n",
    "    \n",
    "    print(f\"mean test score for {k.split('_')[0]} \\t: `{round(mean(current), 6)}`  \")\n",
    "\n",
    "for j in saved_scores.keys():\n",
    "    times.append(saved_scores[j][\"Time\"])\n",
    "print(f\"\\nMean time to train to F1 score ≥ {round(min_score, 3)}:   `{round(mean(times), 5)}` seconds, stdev: `{round(stdev(times), 5)}`s  \")\n",
    "print(f'Total time: `{round(sum(times), 5)}` seconds.  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-treasure",
   "metadata": {},
   "source": [
    "### And if desired, we can print the entire raw SCORES dictionary for visual confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-slovak",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for i in SCORES:\n",
    "    print('```  ')\n",
    "    pprint(SCORES[i])\n",
    "    print('```  ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARISE",
   "language": "python",
   "name": "arise"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
