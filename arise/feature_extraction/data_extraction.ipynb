{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-climate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, extract_relevant_features\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = \"../\"\n",
    "DATA_DIR = \"../data_28/\" # dataset_{00..27}.csv\n",
    "\n",
    "def get_i_datasets(numSets):\n",
    "    ''' Returns an aggregated DataFrame object containing data from the first i datasets in ../data_28/ '''\n",
    "    assert numSets in range(1, 29)\n",
    "    \n",
    "    master = pd.DataFrame(columns=['id', 'index', 'datetime', 'rtt']) # Create empty dataframe to append new DataFrames to.\n",
    "\n",
    "    for i in range(numSets):\n",
    "        f = DATA_DIR + f\"dataset_{i:02d}.csv\" # get file path\n",
    "        df = pd.read_csv(f) # Read raw csv\n",
    "        df.rename(columns = {'Unnamed: 0':'index'}, inplace = True) # rename index column to 'index'\n",
    "\n",
    "        df.insert(0, 'id', i) # create and populate ID column as first entry in dataframe\n",
    "#         df['rtt'] = df['rtt'].fillna(0) # replace NaN's with 0\n",
    "#         print(df)\n",
    "        master = master.append(df, ignore_index = True)\n",
    "    return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames to extract features from\n",
    "master = get_i_datasets(28)\n",
    "half = get_i_datasets(14)\n",
    "quarter = get_i_datasets(7)\n",
    "tiny = get_i_datasets(3)\n",
    "\n",
    "# master.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-collection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# which dataset to use for right now\n",
    "\n",
    "# df = tiny    # 3 \n",
    "df = quarter # 7\n",
    "# df = half    # 14\n",
    "# df = master  # 28\n",
    "\n",
    "# Get last entry in 'id' column, aka the number of datasets to loop through.\n",
    "num = df.loc[df.index[-1], 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-establishment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print RTT diagrams of currently selected DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "FIGURE_DIR = \"../data_28/figures/\" # root/data_28/figures\n",
    "\n",
    "for i in range(num + 1):\n",
    "#     df[df['id'] == i]['rtt'].plot(use_index=False, x='index', subplots=True, sharex=True, figsize=(16,4))\n",
    "    current_df = df[df['id'] == i]['rtt']\n",
    "    current_df.plot(figsize=(16,4))\n",
    "    \n",
    "    plt.title(f\"Dataset {i:02d} RTT\", loc='left')\n",
    "    plt.grid(axis='y', linestyle='-', linewidth=.4) # x, y, or both\n",
    "    plt.xlabel('Measurement Index')\n",
    "    plt.ylabel('Round Trip Time (ms)')\n",
    "    # plt.yscale('log') # useful for datasets with extreme variations in RTTs\n",
    "    \n",
    "    # Uncomment to enable writing figures to FIGURE_DIR\n",
    "    # plt.savefig(FIGURE_DIR + f'dataset{i:02d}.png', bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Feature Extraction\n",
    "# note: we don't need to include column_sort='datetime' since data is already sorted in ascending order\n",
    "\n",
    "# features = extract_features(df, column_id=\"id\", column_value=\"rtt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_progress_bar = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Feature Extraction\n",
    "# https://tsfresh.readthedocs.io/en/latest/text/feature_extraction_settings.html\n",
    "\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "\n",
    "# Create and assign custom settings\n",
    "default = ComprehensiveFCParameters() # CompFCP defaults to extracting all default features\n",
    "# custom = {\n",
    "#     \"length\": None,\n",
    "#     \"large_standard_deviation\": [{\"r\": 0.05}, {\"r\": 0.1}]\n",
    "# }\n",
    "\n",
    "# https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html#tsfresh.feature_extraction.feature_calculators.mean_change\n",
    "\n",
    "custom = {\n",
    "    \"length\": None,                       # number of entries in each time series\n",
    "#     \"mean_change\": None,                  # change in mean between subsequent time series\n",
    "    \"quantile\": [{\"q\": 0.9}],             # calculates the q quantile of the series; the output x is the latency val for which q% of measurements are <= x\n",
    "#     \"ratio_beyond_r_sigma\": [{\"r\": 1.0}], # ratio of measurements beyond r*std. dev. (sigma) from the mean\n",
    "    \"approximate_entropy\": [{'m': 1, 'r': 1}],          # approximate entropy; https://en.wikipedia.org/wiki/Approximate_entropy\n",
    "    \"standard_deviation\": None,           # standard deviation\n",
    "    \"mean\": None\n",
    "#     \"variance\": None,\n",
    "#     \"variance_larger_than_standard_deviation\": None,\n",
    "#     \"variation_coefficient\": None,        # standard error / mean\n",
    "#     \"autocorrelation\": [{'lag': 1}],    # similarity between observations by the lag between them; https://en.wikipedia.org/wiki/Autocorrelation#Estimation\n",
    "#     \"binned_entropy\": [{\"max_bins\": 100}]\n",
    "}\n",
    "\n",
    "# Perform feature extraction with custom settings\n",
    "features = extract_features(df, default_fc_parameters=custom, column_id=\"id\", column_sort=\"index\", column_value=\"rtt\", disable_progressbar=disable_progress_bar)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Features\n",
    "# https://tsfresh.readthedocs.io/en/latest/text/how_to_add_custom_feature.html\n",
    "\n",
    "from tsfresh.feature_extraction.feature_calculators import set_property\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "import numpy as np\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def num_outages(x):\n",
    "    \"\"\"\n",
    "    Returns the count of measurements reading 0 in a time series x.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :return: the value of this feature\n",
    "    :return type: int\n",
    "    \"\"\"\n",
    "    return np.count_nonzero(x == 0)\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def count_nonzero(x):\n",
    "    \"\"\" Returns the number of nonzero measurements in the time series x. \"\"\"\n",
    "    return np.count_nonzero(x)\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def noise_threshold(x):\n",
    "    \"\"\" Returns the noise threshold for a time series, based on the heuristic of 1.5 * the upper IQR. \"\"\"\n",
    "    return np.percentile(x, 75) * 1.5\n",
    "\n",
    "\n",
    "# Add custom features to list of feature calculators:\n",
    "feature_calculators.__dict__[\"num_outages\"] = num_outages\n",
    "feature_calculators.__dict__[\"count_nonzero\"] = count_nonzero\n",
    "feature_calculators.__dict__[\"noise_threshold\"] = noise_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Feature Extraction\n",
    "# https://tsfresh.readthedocs.io/en/latest/text/feature_extraction_settings.html\n",
    "\n",
    "custom = {\n",
    "    \"length\": None,                       # number of entries in each time series\n",
    "#     \"quantile\": [{\"q\": 0.9}],             # calculates the q quantile of the series; the output x is the latency val for which q% of measurements are <= x\n",
    "#     \"approximate_entropy\": [{'m': 1, 'r': 1}],          # approximate entropy; https://en.wikipedia.org/wiki/Approximate_entropy\n",
    "#     \"standard_deviation\": None,           # standard deviation\n",
    "#     \"mean\": None,\n",
    "#     \"variance\": None,\n",
    "#     \"variation_coefficient\": None,        # standard error / mean\n",
    "#     \"binned_entropy\": [{\"max_bins\": 100}],\n",
    "    \"num_outages\": None,\n",
    "    \"count_nonzero\": None,\n",
    "    \"noise_threshold\": None,\n",
    "}\n",
    "\n",
    "disable_progress_bar = True\n",
    "\n",
    "# Perform feature extraction with custom settings\n",
    "features = extract_features(df, default_fc_parameters=custom, column_id=\"id\", column_sort=\"index\", column_value=\"rtt\", disable_progressbar=disable_progress_bar)\n",
    "\n",
    "print(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emerge_env",
   "language": "python",
   "name": "emerge_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
